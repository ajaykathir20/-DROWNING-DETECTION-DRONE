# -*- coding: utf-8 -*-
"""TARP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JCyL--5CO4bNGkaHzT6YW0aKnkFkIr18
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

import os
os.chdir('/content/drive/My Drive/tarpData')

batch_size = 32
img_height = 224
img_width = 224

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
  '/content/drive/My Drive/tarpData/drown/train',
  validation_split=0.2,
  subset="training",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
  '/content/drive/My Drive/tarpData/drown/valid',
  validation_split=0.2,
  subset="validation",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

data_augmentation = tf.keras.Sequential([
  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),
  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),
  tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),
])

preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input

AUTOTUNE = tf.data.experimental.AUTOTUNE

train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)

train_ds = train_ds.map(lambda x, y: (data_augmentation(x), y))
train_ds = train_ds.map(lambda x, y: (preprocess_input(x), y))
val_ds = val_ds.map(lambda x, y: (preprocess_input(x), y))

base_model = tf.keras.applications.MobileNetV2(input_shape=(img_height, img_width, 3),
                                               include_top=False,
                                               weights='imagenet')

base_model.trainable = False

model = tf.keras.Sequential([
  base_model,
  tf.keras.layers.GlobalAveragePooling2D(),
  tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

epochs = 10

history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=epochs
)

test_ds = tf.keras.preprocessing.image_dataset_from_directory(
  '/content/drive/My Drive/tarpData/drown/test',
  image_size=(img_height, img_width),
  batch_size=batch_size)

test_ds = test_ds.map(lambda x, y: (preprocess_input(x), y))

loss, accuracy = model.evaluate(test_ds)
print('Test accuracy:', accuracy)

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(16, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

from sklearn.metrics import roc_curve, auc

test_ds = tf.keras.preprocessing.image_dataset_from_directory(
  '/content/drive/My Drive/tarpData/drown/test',
  image_size=(img_height, img_width),
  batch_size=batch_size)

test_ds = test_ds.map(lambda x, y: (preprocess_input(x), y))

y_true = []
y_scores = []

for x, y in test_ds:
    y_true.extend(y.numpy())
    y_scores.extend(model.predict(x).flatten())

fpr, tpr, thresholds = roc_curve(y_true, y_scores)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 8))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()

# TESTING WITH AN INPUT
sample_image = tf.keras.preprocessing.image.load_img('/content/drive/MyDrive/tarpData/image1+-+
 .jpg', target_size=(img_height, img_width))
sample_image

sample_image = tf.keras.preprocessing.image.img_to_array(sample_image)

sample_image = np.expand_dims(sample_image, axis=0)

sample_image = preprocess_input(sample_image)

prediction = model.predict(sample_image)
prediction

if prediction > 0.1:
    print('The sample image does not depict drowning.')
else:
    print('The sample image depicts drowning.')